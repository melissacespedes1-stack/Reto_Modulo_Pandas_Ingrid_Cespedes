{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa9371a",
   "metadata": {},
   "source": [
    "# üöÄ Reto de Ingenier√≠a de Datos: Optimizaci√≥n y Visualizaci√≥n\n",
    "**Diplomado en Estrategias de Datos - USTA**  \n",
    "* **Estudiante:** Melissa C√©spedes  \n",
    "* **Fecha:** 2026-01-03  \n",
    "\n",
    "**Descripci√≥n:** En este cuaderno aplico t√©cnicas de optimizaci√≥n de memoria (*downcasting* y *category*), ingenier√≠a de variables **vectorizada** y visualizaci√≥n avanzada sobre un dataset de viajes de Taxi en NYC.  \n",
    "El objetivo es demostrar buenas pr√°cticas de Ingenier√≠a de Datos: **eficiencia**, **reproducibilidad** y **storytelling**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1) Configuraci√≥n inicial\n",
    "# ================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "from fpdf import FPDF\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9686d19",
   "metadata": {},
   "source": [
    "## 2) Carga del dataset y diagn√≥stico de memoria (ANTES)\n",
    "Primero cargamos el dataset **sin optimizar** para tener una l√≠nea base clara de cu√°nta memoria consume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ddd851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2.1) Ubicar el archivo (ajusta si tu ruta es distinta)\n",
    "# ================================\n",
    "CANDIDATE_PATHS = [\n",
    "    Path(\"data/train.csv\"),\n",
    "    Path(\"data/nyc_taxi_train.csv\"),\n",
    "    Path(\"train.csv\"),\n",
    "    Path(\"nyc_taxi_train.csv\"),\n",
    "]\n",
    "\n",
    "DATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encontr√© el CSV. Revisa DATASET_INFO.md en el repo y ajusta CANDIDATE_PATHS. \"\n",
    "        \"Rutas probadas: \" + \", \".join(map(str, CANDIDATE_PATHS))\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Usando:\", DATA_PATH)\n",
    "\n",
    "# ================================\n",
    "# 2.2) Cargar (baseline: sin optimizar)\n",
    "# ================================\n",
    "t0 = perf_counter()\n",
    "df_raw = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "t1 = perf_counter()\n",
    "\n",
    "print(f\"Tiempo de carga (sin optimizar): {t1 - t0:0.2f} s\")\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "df_raw.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagn√≥stico de memoria real (deep)\n",
    "def mem_mb(df: pd.DataFrame) -> float:\n",
    "    return df.memory_usage(deep=True).sum() / (1024**2)\n",
    "\n",
    "mem_before = mem_mb(df_raw)\n",
    "print(f\"Memoria ANTES: {mem_before:,.2f} MB\")\n",
    "\n",
    "df_raw.info(memory_usage=\"deep\", show_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e96a06",
   "metadata": {},
   "source": [
    "## 3) Optimizaci√≥n (Pandas Pro)\n",
    "Buscamos reducir **al menos 50%** de memoria sin perder informaci√≥n.\n",
    "\n",
    "Aplicamos:\n",
    "- **Downcasting** de num√©ricos (`int64 ‚Üí int16/int32`, `float64 ‚Üí float32`).\n",
    "- Conversi√≥n de `object ‚Üí category` cuando tiene repetici√≥n (baja cardinalidad relativa).\n",
    "- Conversi√≥n de columnas de fecha/hora a `datetime64[ns]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3.1) Helpers de optimizaci√≥n\n",
    "# ================================\n",
    "def detect_datetime_columns(columns) -> list[str]:\n",
    "    cols = []\n",
    "    for c in columns:\n",
    "        c_low = c.lower()\n",
    "        if \"datetime\" in c_low or \"timestamp\" in c_low:\n",
    "            cols.append(c)\n",
    "        if c_low.endswith(\"_dt\") or c_low.endswith(\"_date\") or c_low.endswith(\"_time\"):\n",
    "            cols.append(c)\n",
    "    # quitar duplicados preservando orden\n",
    "    seen, out = set(), []\n",
    "    for c in cols:\n",
    "        if c not in seen:\n",
    "            out.append(c); seen.add(c)\n",
    "    return out\n",
    "\n",
    "def optimize_dataframe(df: pd.DataFrame, category_threshold: float = 0.5) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Retorna df optimizado y un reporte de conversiones.\"\"\"\n",
    "    df_opt = df.copy()\n",
    "    report_rows = []\n",
    "\n",
    "    # 1) Datetimes\n",
    "    dt_cols = [c for c in detect_datetime_columns(df_opt.columns) if c in df_opt.columns]\n",
    "    for c in dt_cols:\n",
    "        before = df_opt[c].dtype\n",
    "        df_opt[c] = pd.to_datetime(df_opt[c], errors=\"coerce\")\n",
    "        report_rows.append((c, str(before), str(df_opt[c].dtype), \"to_datetime\"))\n",
    "\n",
    "    # 2) Downcast num√©ricos\n",
    "    for c in df_opt.columns:\n",
    "        col = df_opt[c]\n",
    "        if pd.api.types.is_integer_dtype(col):\n",
    "            before = col.dtype\n",
    "            df_opt[c] = pd.to_numeric(col, downcast=\"integer\")\n",
    "            if df_opt[c].dtype != before:\n",
    "                report_rows.append((c, str(before), str(df_opt[c].dtype), \"downcast_int\"))\n",
    "        elif pd.api.types.is_float_dtype(col):\n",
    "            before = col.dtype\n",
    "            df_opt[c] = pd.to_numeric(col, downcast=\"float\")\n",
    "            if df_opt[c].dtype != before:\n",
    "                report_rows.append((c, str(before), str(df_opt[c].dtype), \"downcast_float\"))\n",
    "\n",
    "    # 3) Objects ‚Üí category cuando conviene\n",
    "    obj_cols = [c for c in df_opt.columns if df_opt[c].dtype == \"object\"]\n",
    "    for c in obj_cols:\n",
    "        n = len(df_opt[c])\n",
    "        nunique = df_opt[c].nunique(dropna=False)\n",
    "        ratio = nunique / max(n, 1)\n",
    "\n",
    "        # Heur√≠stica: si hay repetici√≥n (ratio bajo), category ahorra memoria\n",
    "        if ratio <= category_threshold:\n",
    "            before = df_opt[c].dtype\n",
    "            df_opt[c] = df_opt[c].astype(\"category\")\n",
    "            report_rows.append((c, str(before), str(df_opt[c].dtype), f\"to_category (ratio={ratio:0.4f})\"))\n",
    "\n",
    "    report = pd.DataFrame(report_rows, columns=[\"columna\", \"dtype_antes\", \"dtype_despues\", \"accion\"])\n",
    "    return df_opt, report\n",
    "\n",
    "t0 = perf_counter()\n",
    "df_opt, opt_report = optimize_dataframe(df_raw)\n",
    "t1 = perf_counter()\n",
    "\n",
    "print(f\"Tiempo de optimizaci√≥n: {t1 - t0:0.2f} s\")\n",
    "opt_report.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_after = mem_mb(df_opt)\n",
    "reduction_pct = (1 - mem_after / mem_before) * 100\n",
    "\n",
    "print(f\"Memoria DESPU√âS: {mem_after:,.2f} MB\")\n",
    "print(f\"Reducci√≥n: {reduction_pct:0.2f}%\")\n",
    "\n",
    "# Comprobaciones simples de 'no perder informaci√≥n'\n",
    "assert df_opt.shape == df_raw.shape\n",
    "assert df_opt.isna().sum().sum() == df_raw.isna().sum().sum()\n",
    "\n",
    "df_opt.info(memory_usage=\"deep\", show_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a93753",
   "metadata": {},
   "source": [
    "## 4) Ingenier√≠a de variables (vectorizada)\n",
    "Aqu√≠ creamos variables **sin bucles** (sin `.apply` fila-a-fila):\n",
    "\n",
    "- Variables temporales: hora, d√≠a de la semana, mes.\n",
    "- Variable geoespacial: distancia (Haversine) entre punto de inicio y fin (si existen lat/lon).\n",
    "- Variables de negocio: velocidad (km/h) y flags de viajes an√≥malos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4.1) Detectar columnas t√≠picas del dataset de Taxi\n",
    "# ================================\n",
    "cols = set(df_opt.columns.str.lower())\n",
    "\n",
    "pickup_dt_candidates = [\"pickup_datetime\", \"tpep_pickup_datetime\", \"pickup_timestamp\"]\n",
    "dropoff_dt_candidates = [\"dropoff_datetime\", \"tpep_dropoff_datetime\", \"dropoff_timestamp\"]\n",
    "duration_candidates = [\"trip_duration\", \"duration\", \"trip_time\", \"trip_seconds\"]\n",
    "\n",
    "def first_existing(cands):\n",
    "    for c in cands:\n",
    "        if c in cols:\n",
    "            return next(orig for orig in df_opt.columns if orig.lower() == c)\n",
    "    return None\n",
    "\n",
    "pickup_dt = first_existing(pickup_dt_candidates)\n",
    "dropoff_dt = first_existing(dropoff_dt_candidates)\n",
    "duration_col = first_existing(duration_candidates)\n",
    "\n",
    "latlon_map = {\n",
    "    \"pickup_latitude\": first_existing([\"pickup_latitude\", \"pickup_lat\", \"start_lat\", \"pick_lat\"]),\n",
    "    \"pickup_longitude\": first_existing([\"pickup_longitude\", \"pickup_lon\", \"start_lon\", \"pick_lon\"]),\n",
    "    \"dropoff_latitude\": first_existing([\"dropoff_latitude\", \"dropoff_lat\", \"end_lat\", \"drop_lat\"]),\n",
    "    \"dropoff_longitude\": first_existing([\"dropoff_longitude\", \"dropoff_lon\", \"end_lon\", \"drop_lon\"]),\n",
    "}\n",
    "\n",
    "print(\"pickup_dt:\", pickup_dt)\n",
    "print(\"dropoff_dt:\", dropoff_dt)\n",
    "print(\"duration_col:\", duration_col)\n",
    "print(\"lat/lon:\", latlon_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4.2) Features temporales (vectorizado)\n",
    "# ================================\n",
    "df = df_opt.copy()\n",
    "\n",
    "if pickup_dt is not None and np.issubdtype(df[pickup_dt].dtype, np.datetime64):\n",
    "    df = df.assign(\n",
    "        pickup_hour=df[pickup_dt].dt.hour.astype(\"int8\"),\n",
    "        pickup_dow=df[pickup_dt].dt.dayofweek.astype(\"int8\"),\n",
    "        pickup_month=df[pickup_dt].dt.month.astype(\"int8\")\n",
    "    )\n",
    "\n",
    "if pickup_dt is not None and dropoff_dt is not None and np.issubdtype(df[dropoff_dt].dtype, np.datetime64):\n",
    "    trip_seconds = (df[dropoff_dt] - df[pickup_dt]).dt.total_seconds()\n",
    "    df = df.assign(trip_seconds=trip_seconds.astype(\"float32\"))\n",
    "\n",
    "if duration_col is not None and \"trip_seconds\" not in df.columns:\n",
    "    df = df.assign(trip_seconds=pd.to_numeric(df[duration_col], errors=\"coerce\").astype(\"float32\"))\n",
    "\n",
    "df[[\"trip_seconds\"]].describe().T if \"trip_seconds\" in df.columns else df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f036a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4.3) Distancia Haversine (vectorizado) si hay coordenadas\n",
    "# ================================\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1 = np.radians(lat1); lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2); lon2 = np.radians(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371.0 * c  # km\n",
    "\n",
    "have_geo = all(v is not None for v in latlon_map.values())\n",
    "if have_geo:\n",
    "    dist_km = haversine_km(\n",
    "        df[latlon_map[\"pickup_latitude\"]].astype(\"float32\"),\n",
    "        df[latlon_map[\"pickup_longitude\"]].astype(\"float32\"),\n",
    "        df[latlon_map[\"dropoff_latitude\"]].astype(\"float32\"),\n",
    "        df[latlon_map[\"dropoff_longitude\"]].astype(\"float32\"),\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "    df = df.assign(distance_km=dist_km)\n",
    "\n",
    "    if \"trip_seconds\" in df.columns:\n",
    "        hours = (df[\"trip_seconds\"] / 3600).replace(0, np.nan)\n",
    "        df = df.assign(speed_kmh=(df[\"distance_km\"] / hours).astype(\"float32\"))\n",
    "\n",
    "df[[\"distance_km\", \"speed_kmh\"]].describe().T if have_geo and \"trip_seconds\" in df.columns else df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721dd92",
   "metadata": {},
   "source": [
    "## 5) Visualizaci√≥n profesional (Storytelling)\n",
    "Objetivo: crear gr√°ficos que **respondan preguntas** y eviten ruido visual.\n",
    "\n",
    "Lo que demostramos:\n",
    "- **Distribuciones sesgadas**: escala logar√≠tmica para entender colas largas.\n",
    "- **Overplotting**: `hexbin` o `alpha` + recorte.\n",
    "- **Menos chartjunk**: t√≠tulos claros, ejes consistentes, spines innecesarias fuera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578dd391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta para guardar figuras (para el PDF)\n",
    "ASSETS_DIR = Path(\"report_assets\")\n",
    "ASSETS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def clean_axes(ax):\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5.1) Distribuci√≥n (log) de duraci√≥n o variable num√©rica\n",
    "# ================================\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "if \"trip_seconds\" in df.columns:\n",
    "    x = df[\"trip_seconds\"].dropna()\n",
    "    x = x[(x > 0) & (x < x.quantile(0.999))]\n",
    "    ax.hist(x, bins=60, log=True)\n",
    "    ax.set_title(\"Distribuci√≥n de duraci√≥n del viaje (frecuencia en escala log)\")\n",
    "    ax.set_xlabel(\"Segundos\")\n",
    "    ax.set_ylabel(\"Frecuencia (log)\")\n",
    "else:\n",
    "    any_num = df.select_dtypes(include=\"number\").columns[0]\n",
    "    x = df[any_num].dropna()\n",
    "    ax.hist(x, bins=60, log=True)\n",
    "    ax.set_title(f\"Distribuci√≥n de {any_num} (frecuencia en escala log)\")\n",
    "    ax.set_xlabel(any_num)\n",
    "    ax.set_ylabel(\"Frecuencia (log)\")\n",
    "\n",
    "clean_axes(ax)\n",
    "plt.tight_layout()\n",
    "\n",
    "p1 = ASSETS_DIR / \"hist_log_duration.png\"\n",
    "fig.savefig(p1, dpi=160)\n",
    "p1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5.2) Overplotting geoespacial: Hexbin de puntos de pickup\n",
    "# ================================\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "\n",
    "if have_geo:\n",
    "    x = df[latlon_map[\"pickup_longitude\"]]\n",
    "    y = df[latlon_map[\"pickup_latitude\"]]\n",
    "    m = x.between(-75, -72) & y.between(40, 42)\n",
    "    x, y = x[m], y[m]\n",
    "\n",
    "    hb = ax.hexbin(x, y, gridsize=120, mincnt=1)\n",
    "    ax.set_title(\"Densidad de puntos de recogida (hexbin)\")\n",
    "    ax.set_xlabel(\"Longitud\")\n",
    "    ax.set_ylabel(\"Latitud\")\n",
    "    fig.colorbar(hb, ax=ax, label=\"Conteo por hex√°gono\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No se encontraron columnas de lat/lon.\", ha=\"center\", va=\"center\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "p2 = ASSETS_DIR / \"hexbin_pickup.png\"\n",
    "fig.savefig(p2, dpi=160)\n",
    "p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ea0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5.3) Heatmap: demanda por hora vs d√≠a\n",
    "# ================================\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "if {\"pickup_hour\", \"pickup_dow\"}.issubset(df.columns):\n",
    "    heat = (\n",
    "        df.groupby([\"pickup_dow\", \"pickup_hour\"])\n",
    "          .size()\n",
    "          .unstack(fill_value=0)\n",
    "          .astype(\"int32\")\n",
    "    )\n",
    "    sns.heatmap(heat, ax=ax, cbar_kws={\"label\": \"N√∫mero de viajes\"})\n",
    "    ax.set_title(\"Demanda de viajes por D√≠a de semana vs Hora\")\n",
    "    ax.set_xlabel(\"Hora del d√≠a\")\n",
    "    ax.set_ylabel(\"D√≠a de la semana (0=Lun ... 6=Dom)\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No se encontraron variables temporales (pickup_hour/pickup_dow).\", ha=\"center\", va=\"center\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "p3 = ASSETS_DIR / \"heatmap_dow_hour.png\"\n",
    "fig.savefig(p3, dpi=160)\n",
    "p3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aad5f1",
   "metadata": {},
   "source": [
    "## 6) Capstone: Reporte PDF autom√°tico\n",
    "Generamos un PDF que:\n",
    "- resume la reducci√≥n de memoria;\n",
    "- incluye gr√°ficos clave;\n",
    "- queda como entregable final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3112238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 6.1) Insights para el reporte\n",
    "# ================================\n",
    "insights = []\n",
    "insights.append(f\"Dataset: {df.shape[0]:,} filas y {df.shape[1]:,} columnas.\")\n",
    "insights.append(f\"Memoria antes: {mem_before:,.2f} MB.\")\n",
    "insights.append(f\"Memoria despu√©s: {mem_after:,.2f} MB.\")\n",
    "insights.append(f\"Reducci√≥n: {reduction_pct:0.2f}%.\")\n",
    "\n",
    "if {\"pickup_hour\", \"pickup_dow\"}.issubset(df.columns):\n",
    "    peak_hour = df[\"pickup_hour\"].value_counts().idxmax()\n",
    "    peak_dow = df[\"pickup_dow\"].value_counts().idxmax()\n",
    "    insights.append(f\"Pico de demanda: hora {int(peak_hour)} y d√≠a {int(peak_dow)} (0=Lun ... 6=Dom).\")\n",
    "\n",
    "if \"distance_km\" in df.columns:\n",
    "    insights.append(f\"Distancia mediana: {float(df['distance_km'].median()):0.2f} km.\")\n",
    "\n",
    "if \"trip_seconds\" in df.columns:\n",
    "    insights.append(f\"Duraci√≥n mediana: {float(df['trip_seconds'].median())/60:0.1f} min.\")\n",
    "\n",
    "for s in insights:\n",
    "    print('‚Ä¢', s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fece41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 6.2) PDF con FPDF\n",
    "# ================================\n",
    "REPORT_PATH = Path(\"Reporte_Reto_Modulo1.pdf\")\n",
    "\n",
    "pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "pdf.set_auto_page_break(auto=True, margin=12)\n",
    "\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", \"B\", 14)\n",
    "pdf.multi_cell(0, 8, \"Reto de Ingenier√≠a de Datos: Optimizaci√≥n y Visualizaci√≥n\")\n",
    "pdf.set_font(\"Arial\", \"\", 11)\n",
    "pdf.multi_cell(0, 6, \"Diplomado en Estrategias de Datos - USTA\")\n",
    "pdf.ln(2)\n",
    "pdf.multi_cell(0, 6, \"Estudiante: Cristian Rojas\")\n",
    "pdf.multi_cell(0, 6, \"Fecha: 2026-01-03\")\n",
    "\n",
    "pdf.ln(4)\n",
    "pdf.set_font(\"Arial\", \"B\", 12)\n",
    "pdf.multi_cell(0, 7, \"Resumen ejecutivo\")\n",
    "pdf.set_font(\"Arial\", \"\", 11)\n",
    "for s in insights:\n",
    "    pdf.multi_cell(0, 6, f\"- {s}\")\n",
    "\n",
    "def add_figure(title: str, path: Path):\n",
    "    if not path.exists():\n",
    "        return\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", \"B\", 12)\n",
    "    pdf.multi_cell(0, 7, title)\n",
    "    pdf.ln(2)\n",
    "    pdf.image(str(path), x=12, w=185)\n",
    "\n",
    "add_figure(\"Figura 1 ‚Äî Distribuci√≥n (log) de una variable clave\", p1)\n",
    "add_figure(\"Figura 2 ‚Äî Densidad geoespacial (hexbin)\", p2)\n",
    "add_figure(\"Figura 3 ‚Äî Demanda por d√≠a y hora (heatmap)\", p3)\n",
    "\n",
    "pdf.output(str(REPORT_PATH))\n",
    "REPORT_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182b5ae",
   "metadata": {},
   "source": [
    "## üí° Conclusiones y hallazgos\n",
    "1. **Memoria:** Se logr√≥ una reducci√≥n de memoria (objetivo: ‚â• 50%).  \n",
    "2. **Patrones:** La demanda var√≠a por hora y d√≠a, y la concentraci√≥n espacial se aprecia mejor con `hexbin`.  \n",
    "3. **T√©cnica:** El enfoque vectorizado (Pandas + NumPy) facilita escalar el an√°lisis sin ‚ÄúPython calculadora‚Äù.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
